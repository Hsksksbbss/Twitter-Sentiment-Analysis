# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/160QW_ZK7FLSZe6TALxSUj_P_NNQCn6S8

Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout
from tensorflow.keras.utils import to_categorical

"""Load Dataset"""

df = pd.read_csv("/content/twitter_training.csv")

df.columns = ["ID", "Category", "Sentiment", "Tweet"]

"""Select Features and Labels"""

X = df.iloc[:, 3].astype(str).values
y = df.iloc[:, 2].values

"""Encode labels"""

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)
y = to_categorical(y)

Train-Test Split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

"""Tokenization and Padding"""

max_words = 10000     # Vocabulary size
max_len = 100         # Max length of tweet (truncate/pad)

tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding="post")
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding="post")

"""Build CNN Model"""

model = Sequential([
    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),
    Conv1D(filters=128, kernel_size=5, activation="tanh"),
    GlobalMaxPooling1D(),
    Dense(64, activation="tanh"),
    Dropout(0.5),
    Dense(y.shape[1], activation="softmax")  # output layer
])

model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

"""Train Model"""

history = model.fit(
    X_train_pad, y_train,
    validation_data=(X_test_pad, y_test),
    epochs=13,
    batch_size=128,
    verbose=1
)

""" Evaluate Model"""

loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=0)
print(f"\nâœ… CNN Test Accuracy: {accuracy * 100:.2f}%")

plt.figure(figsize=(12,5))

"""Accuracy Plot"""

plt.subplot(1,2,1)
plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Val Accuracy")
plt.title("CNN Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()

"""Loss Plot"""

plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Val Loss")
plt.title("CNN Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()

plt.show()

